"""
Export SynthText (custom fork with optional lineBB) HDF5 output into
PaddleOCR detector training format.

Output structure example:
  output_dir/
    images/ <exported *.jpg>
    train.txt
    val.txt

Each line of train/val txt:
  relative/path/to/image.jpg\t[JSON_ARRAY]
Where JSON_ARRAY is a list of objects: {"transcription": "", "points": [[x,y],[x2,y2],[...]]}

Default uses word-level boxes (wordBB). If --line_bb is provided and lineBB
annotations exist, line-level boxes are exported instead; fallback order with
--line_bb: lineBB -> wordBB -> charBB. Without --line_bb: wordBB -> charBB.

Author: Generated by tooling.
"""
import argparse
import json
import os
import os.path as osp
import random
from typing import List

import h5py
import numpy as np
from PIL import Image

# -------------- geometry helpers --------------

def _valid_quad(quad: np.ndarray) -> bool:
    return quad.shape == (4,2)

# -------------- extraction --------------

def extract_quads(ds, line_mode: bool) -> List[np.ndarray]:
    quads: List[np.ndarray] = []
    a = ds.attrs
    if line_mode and 'lineBB' in a and getattr(a['lineBB'], 'ndim', 0) == 3:
        lineBB = a['lineBB']
        for i in range(lineBB.shape[-1]):
            quads.append(lineBB[:,:,i].T)
        return quads
    if 'wordBB' in a:
        wordBB = a['wordBB']
        if wordBB.ndim == 2:
            quads.append(wordBB.T)
        elif wordBB.ndim == 3:
            for i in range(wordBB.shape[-1]):
                quads.append(wordBB[:,:,i].T)
        return quads
    if 'charBB' in a and getattr(a['charBB'], 'ndim', 0) == 3:
        charBB = a['charBB']
        for i in range(charBB.shape[-1]):
            quads.append(charBB[:,:,i].T)
    return quads

def extract_texts(ds, line_mode: bool) -> List[str]:
    if 'txt' not in ds.attrs:
        return []
    raw = ds.attrs['txt']
    blocks = [b.decode('ascii', errors='ignore') if isinstance(b,(bytes,bytearray)) else str(b) for b in raw]
    if line_mode and 'lineBB' in ds.attrs:
        out: List[str] = []
        for b in blocks:
            for part in b.split('\n'):
                part = part.strip()
                if part:
                    out.append(part)
        return out
    if 'wordBB' in ds.attrs:
        words: List[str] = []
        for b in blocks:
            words.extend([w for w in b.split() if w])
        return words
    chars: List[str] = []
    for b in blocks:
        for c in b:
            if not c.isspace():
                chars.append(c)
    return chars

# -------------- main conversion --------------

def convert(h5_path: str, out_dir: str, line_bb: bool = False,
            val_ratio: float = 0.05, seed: int = 1337,
            img_ext: str = 'jpg', limit: int = -1) -> None:
    if not osp.isfile(h5_path):
        raise SystemExit(f"Input h5 not found: {h5_path}")
    os.makedirs(out_dir, exist_ok=True)
    img_dir = osp.join(out_dir, 'images')
    os.makedirs(img_dir, exist_ok=True)

    with h5py.File(h5_path, 'r') as db:
        data_group = db['data']
        keys = sorted(list(data_group.keys()))
        if limit > 0:
            keys = keys[:limit]
        rng = random.Random(seed)
        val_count = max(1, int(len(keys) * val_ratio)) if len(keys) > 1 and val_ratio > 0 else 0
        val_set = set(rng.sample(keys, val_count)) if val_count > 0 else set()
        train_lines, val_lines = [], []

        for idx, k in enumerate(keys):
            ds = data_group[k]
            arr = ds[()]
            if arr.ndim == 2:
                arr = np.repeat(arr[...,None], 3, axis=2)
            Image.fromarray(arr.astype('uint8')).save(osp.join(img_dir, f"{k}.{img_ext}"), quality=95)
            rel_path = f"images/{k}.{img_ext}"
            quads = extract_quads(ds, line_mode=line_bb)
            texts = extract_texts(ds, line_mode=line_bb)
            items = []
            # Trust SynthText ordering (already TL,TR,BR,BL). No reordering here.
            for i, q in enumerate(quads):
                if not _valid_quad(q):
                    continue
                trans = texts[i] if i < len(texts) else ""
                items.append({"transcription": trans, "points": [[float(x), float(y)] for x,y in q]})
            line = f"{rel_path}\t{json.dumps(items, ensure_ascii=False) if items else '[]'}"
            (val_lines if k in val_set else train_lines).append(line)
            if (idx+1) % 50 == 0:
                print(f"Processed {idx+1}/{len(keys)} images...")

    with open(osp.join(out_dir, 'train.txt'), 'w', encoding='utf-8') as f:
        f.write('\n'.join(train_lines))
    with open(osp.join(out_dir, 'val.txt'), 'w', encoding='utf-8') as f:
        f.write('\n'.join(val_lines))
    print(f"Done. Train: {len(train_lines)}, Val: {len(val_lines)}, Output: {out_dir}")


def build_argparser():
    p = argparse.ArgumentParser(description='Export SynthText H5 to PaddleOCR detector format (default word-level).')
    p.add_argument('-i','--input', default='results/SynthText.h5', help='Input SynthText HDF5 path')
    p.add_argument('-o','--out_dir', default='paddleocr_data', help='Output directory root')
    p.add_argument('--line_bb', action='store_true', help='Use line-level boxes if lineBB exists (fallback to wordBB)')
    p.add_argument('--val_ratio', type=float, default=0.1, help='Validation split ratio (0-1)')
    p.add_argument('--seed', type=int, default=1337, help='Random seed for split')
    p.add_argument('--img_ext', choices=['jpg','png'], default='jpg', help='Exported image extension')
    p.add_argument('--limit', type=int, default=-1, help='Limit number of images (debug)')
    return p


def main():
    args = build_argparser().parse_args()
    convert(h5_path=args.input, out_dir=args.out_dir, line_bb=args.line_bb,
        val_ratio=args.val_ratio, seed=args.seed,
        img_ext=args.img_ext, limit=args.limit)

if __name__ == '__main__':
    main()
